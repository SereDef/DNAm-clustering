
options(startup.messages = FALSE) # avoid Loading package messages on each worker

# Install if needed
# install.packages(c("bigmemory", "foreach", "future", "doFuture", "doRNG", "progressr"))
# BiocManager::install("sva")

library(doRNG)
# Note: I will use '%dorng%' from the 'doRNG' package instead of '%dopar%'. 
# This ensures that proper, parallel-safe random numbers are produced.

# =================================== CONFIG ===================================

args <- commandArgs(trailingOnly = TRUE)
array <- args[1] # 450K or EPIC

dataset <- "GENR"
timepoint <- "birth"
normalization <- "funcnorm"

use_library = '/home/s.defina/R/x86_64-pc-linux-gnu-library/4.4'
.libPaths(use_library)

input_dir <- '~/MPSR/data'
output_dir <- "~/MPSR/data"

methyl_file <- paste(dataset, array, timepoint, normalization, sep = "_")
plates_file <- paste(dataset, array, timepoint, "plates", sep = "_")

n_cores <- as.numeric(Sys.getenv("SLURM_CPUS_PER_TASK", unset = "1"))
chunk_size <- 1055 # ceiling(n_probes / n_cores) / 2

# ==============================================================================
message("\n=====================================================================")
message("Dataset: ", dataset, 
        "\nArray: ", array, 
        "\nTime point: ", timepoint, 
        "\nNormalization: ", normalization)
message("=====================================================================")

message('\nLoading methylation data...')
x <- bigmemory::attach.big.matrix(file.path(input_dir,
                                            paste0(methyl_file, ".desc")))
message(' * Original dimentions:')
dim(x)

# "High-confidence" CpG list generated by 0.2.cpg_selection.R ------------------
cpgs_to_keep <- scan(file.path(input_dir, 'clean_cpg_list.txt'), 
                     what=character(), quiet = TRUE)
stopifnot(all(cpgs_to_keep %in% rownames(x)))

message(' * Retaining: ', length(cpgs_to_keep), ' CpGs.')

# Batch effects information (i.e. plate) ---------------------------------------
plate_info <- readRDS(file.path(input_dir, paste0(plates_file,'.rds')))

# Make sure IDs are in the same order 
plate_info <- plate_info[match(colnames(x), plate_info$Sample_ID), ]
stopifnot(all(colnames(x) == plate_info$Sample_ID))

# x <- x[, plate_info$Sample_ID]
# dim(x)

batch <- plate_info$Sample_Plate

message(' * Plates:')
table(batch)

# ==============================================================================
# BATCH CORRECTION
# ==============================================================================

# This does not account for non-normality and only fixed effects of plates 
# library(limma)
# x_corrected <- limma::removeBatchEffect(x, batch = batch)

# Save descriptors to pass them to parallel workers
x_desc <- file.path(input_dir, paste0(methyl_file, ".desc"))
filtered_desc <- file.path(output_dir, paste0(methyl_file, "_filtered.desc"))
corrected_desc <- file.path(output_dir, paste0(methyl_file, "_clean.desc"))

# Create output big.matrix
n_probes <- length(cpgs_to_keep)
n_samples <- ncol(x)

# Clean up previous matrices if necessary
remove_and_generate <- function(desc) {
  
  if (file.exists(desc)) {
    warning(' * "', desc, '" already exists, removing it.')
    file.remove(desc)
    file.remove(gsub('.desc', '.bin', desc))
  }
  
  message('Generate output methylation matrix...')
  new_x <- bigmemory::filebacked.big.matrix(
    nrow = n_probes,
    ncol = n_samples,
    type = "double",
    backingpath = output_dir,
    descriptorfile = basename(desc),
    backingfile = gsub('.desc', '.bin', basename(desc)),
    dimnames = list(cpgs_to_keep, colnames(x))
  )
  
  return(new_x)
}
filtered_x <- remove_and_generate(filtered_desc)
corrected_x <- remove_and_generate(corrected_desc)


# Chunks of CpGs to process in parallel
chunk_seq <- split(cpgs_to_keep,
                   ceiling(seq_along(cpgs_to_keep) / chunk_size))

# Parallel-safe reproducibility
RNGkind("L'Ecuyer-CMRG")
set.seed(123)

# Parallel-safe progress updates (does not work properly in this SLURM setup)
# progressr::handlers(global = TRUE)
# # progressr::handlers("txtprogressbar")
# progressr::handlers(list(
#   bar = progressr::handler_progress(
#     format   = ":current/:total [:bar] :percent in :elapsed",
#     width    = 60, complete = "="),
#   file = progressr::handler_filesize(
#     file = file.path(output_dir, "slurm.progress.0.3"),
#     intrusiveness = 0)))

message('Running analysis...')
# Set up parallel backend
future::plan(future::multisession, workers = n_cores)
doFuture::registerDoFuture()

# progressr::with_progress({
#   p <- progressr::progressor(steps = length(chunk_seq))
  
# Run ComBat in parallel
foreach::foreach(chunk = chunk_seq,
                 .packages = c("bigmemory", "sva"),
                 .export = c("batch", "x_desc", "corrected_desc"),
                 .combine = 'c') %dorng% {
          
        # Note: with future framework I need to re-attach matrices
        # this adds a little overhead but ensures the memory pointers are not
        # corrupted -> recommended pipeline on SLURM clusters 
        x <- bigmemory::attach.big.matrix(x_desc, readonly = TRUE, lockfile = TRUE)
        filtered_x <- bigmemory::attach.big.matrix(filtered_desc, lockfile = TRUE)
        corrected_x <- bigmemory::attach.big.matrix(corrected_desc, lockfile = TRUE)
        
        adjusted_chunk <- NULL
        
        tryCatch({
          data_chunk <- x[chunk, ]
          
          filtered_x[chunk, ] <- data_chunk
          
          # Run ComBat (non-parametric to avoid normality assumption)
          adjusted_chunk <- suppressWarnings(suppressMessages(
            sva::ComBat(dat = data_chunk, batch = batch, par.prior = FALSE)))
          
          
        }, error = function(e) {
          message("Chunk failed: ", conditionMessage(e))
        })
        
        if (!is.null(adjusted_chunk)) {
          # Write corrected values
          corrected_x[chunk, ] <- adjusted_chunk
        }
        
        # p()  # Advance progress bar
        
        # Suppress result collection
        invisible(NULL)
  }
# })
# flush.console()

future::plan(future::sequential)

warnings()

# checking ---------------------------------------------------------------------

message('Checking batch correction...')
dim(x)
dim(corrected_x)

set.seed(123)
random_cpgs <- sample(rownames(corrected_x), 1000)
# Check these are the same 
print(random_cpgs[1:3])

x_subset <- x[random_cpgs, ]
corrected_x_subset <- corrected_x[random_cpgs, ]

# Compute correlations row-wise
cors <- mapply(function(orig, corr) cor(orig, corr, method='spearman'),
               split(x_subset, row(x_subset)),
               split(corrected_x_subset, row(corrected_x_subset)))

# Name and print results nicely
# names(cors) <- random_cpgs
# print(cors_450K)
message('Pre-post correction correlations (sample n = 1000):')
print(summary(cors))
